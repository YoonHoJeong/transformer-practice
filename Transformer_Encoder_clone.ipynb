{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformer-Encoder-clone",
      "provenance": [],
      "mount_file_id": "1ULKZbEpixjJK57cXWKgW4msYc2a3tkZS",
      "authorship_tag": "ABX9TyMmQfMLHf/OeNbE1QBLU/02",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YoonHoJeong/transformer-practice/blob/master/Transformer_Encoder_clone.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKaPfb6JKUQF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgNuje97L558",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import sentencepiece as spm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpgr9TdYJR_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_file = \"/content/drive/My Drive/Transformer-Encoder/models/kowiki.model\""
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJrQMJ6zJUOP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c8e621c9-5c6b-4c06-c0bf-615a69bd7fad"
      },
      "source": [
        "vocab = spm.SentencePieceProcessor()\n",
        "vocab.load(vocab_file)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqohPRxiLlp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = [\n",
        "  \"겨울은 추워요.\",\n",
        "  \"감기 조심하세요.\"\n",
        "]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awxX99BMLl-Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "57bff315-b544-4e87-cd87-0485ae090066"
      },
      "source": [
        "# text를 tensor로 변환\n",
        "inputs = []\n",
        "for line in lines:\n",
        "  pieces = vocab.encode_as_pieces(line)\n",
        "  ids = vocab.encode_as_ids(line)\n",
        "  inputs.append(torch.tensor(ids))\n",
        "  print(pieces)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁겨울', '은', '▁추', '워', '요', '.']\n",
            "['▁감', '기', '▁조', '심', '하', '세', '요', '.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BScMRroKKV-n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "44b4af7c-cd48-40bb-d549-19de5a68847e"
      },
      "source": [
        "# 입력 길이가 다르므로 입력 최대 길이에 맟춰 padding(0)을 추가 해 줌\n",
        "inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n",
        "# shape\n",
        "print(inputs.size())\n",
        "# 값\n",
        "print(inputs)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 8])\n",
            "tensor([[3091, 3604,  206, 3958, 3760, 3590,    0,    0],\n",
            "        [ 212, 3605,   53, 3832, 3596, 3682, 3760, 3590]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCHsi997MTRM",
        "colab_type": "text"
      },
      "source": [
        "# Input Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXz25VwkMV09",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "690f6dfe-7d5c-456e-a4b9-3c17f7c82cb2"
      },
      "source": [
        "n_vocab = len(vocab) # vocab count\n",
        "d_hidn = 128 # hidden size\n",
        "nn_emb = nn.Embedding(n_vocab, d_hidn) # embedding 객체\n",
        "\n",
        "input_embs = nn_emb(inputs) # input embedding\n",
        "print(input_embs.size())"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 8, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NX0SDqKEM2eQ",
        "colab_type": "text"
      },
      "source": [
        "- nn.Embedding(input-len, d-hidden)\n",
        "  - 위 함수가 어떤 역할을 수행하는지 알아볼 것\n",
        "  - 아마, d_hidden에 맞춰 input을 embedding으로 만들어주는 미리 학습된 모델이 아닐까 싶음\n",
        "\n",
        "https://wikidocs.net/64779\n",
        "- 파이토치에서는 임베딩 벡터를 사용하는 방법이 크게 2가지가 있다.\n",
        "  1. embedding layer를 구성, 훈련 데이터로부터 처음부터 임베딩 벡터를 학습하는 방법\n",
        "    - **nn.Embedding()**\n",
        "  2. 훈련된 임베딩 벡터들을 가져와 사용하는 방법.\n",
        "\n",
        "- 임베딩 층의 입력 : 입력 시퀀스의 단어들은 모두 정수 인코딩이 되어있어야 한다.\n",
        "  - 특정 단어 → 단어에 부여된 고유 정수값 → 임베딩 층 통과 → 밀집 벡터\n",
        "\n",
        "- 임베딩 층은 input 정수에 대해 밀집 벡터(dense vector)로 맵핑, 이 밀집 벡터는 기존 신경망에서 학습되듯 훈련된다.\n",
        "- 특정 단어는 특정 임베딩 벡터와 맵핑되므로, 갖고 있는 단어에 대한 lookup table이 존재하게 된다.\n",
        "- 해당 단어와 연결된 **임베딩 벡터는 임베딩 층에서 모델의 입력이 되어 역전파 과정에 의해 학습된다.**\n",
        "- 파이토치는 단어 → 정수 인덱스 이후 **one-hot encoding을 수행하지 않는다.** \n",
        "\n",
        "- nn.Embedding(num_embeddings, embedding_dim, padding_idx)\n",
        "  - nn.Embedding은 크게 2가지 인자를 받는다.\n",
        "  1. num_embeddings\n",
        "    : 임베딩할 단어들의 개수.\n",
        "  2. embedding_dim\n",
        "    : 임베딩할 벡터의 차원\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vSPc23qqNPwJ",
        "colab_type": "text"
      },
      "source": [
        "# Positional Embedding\n",
        "- 논문에서, \"임베딩 벡터 내의 차원 인덱스\"가 홀수, 짝수인 \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bORkt1rhM1kF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" sinusoid position embedding \"\"\"\n",
        "def get_sinusoid_encoding_table(n_seq, d_hidn):\n",
        "    def cal_angle(position, i_hidn):\n",
        "        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # dim 2i\n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # dim 2i+1\n",
        "\n",
        "    return sinusoid_table"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsCqw7gpSrR9",
        "colab_type": "text"
      },
      "source": [
        "- positional embedding\n",
        "  1. sequence의 길이\n",
        "  2. d_hidden : 은닉벡터의 차원\n",
        "  - 이 외의 **임베딩이나, 단어의 정보는 사용하지 않는다**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8xwXS_WZNd6J",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c1ec482e-8332-4d40-8bb4-9902d1fe0814"
      },
      "source": [
        "n_seq = 64\n",
        "pos_encoding = get_sinusoid_encoding_table(n_seq, d_hidn)\n",
        "\n",
        "print (pos_encoding.shape) # 크기 출력"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(64, 128)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWk3gKRRTk7w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pos_encoding = torch.FloatTensor(pos_encoding)\n",
        "\n",
        "# positional encoding 값을 embedding instance로 만들어준다.\n",
        "nn_pos = nn.Embedding.from_pretrained(pos_encoding, freeze=True)\n",
        "\n",
        "positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n",
        "pos_mask = inputs.eq(0) # input 값 중 0으로 되어있는 padding을 찾는다.\n",
        "\n",
        "positions.masked_fill_(pos_mask, 0) # \n",
        "pos_embs = nn_pos(positions) # position embedding"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rK5klDsFdaiM",
        "colab_type": "text"
      },
      "source": [
        "from_pretrained() 함수를 통해, pos_encoding 값을 통해 nn_pos라는 layer embedding layer를 구축.\n",
        "\n",
        "freeze = True로 설정했을 때, 학습되지 않는다. 그냥 embedding instance를 생성해준다.\n",
        "\n",
        "[torch.arange()](https://pytorch.org/docs/stable/generated/torch.arange.html) : 주어진 범위 내의 정수를 순서대로 생성.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9GwLIIdTRmz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" positional embedding과 input embedding을 말그대로 더해준다.\n",
        " 두개의 임베딩은 같은 차원이기 때문에 가능 \"\"\"\n",
        "input_sums = input_embs + pos_embs\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5ZmYLt6jHEi",
        "colab_type": "text"
      },
      "source": [
        "# 3. Scaled Dot Product Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Od1eq9HRjFgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# self-attention이므로 Q,K,V 모두가 똑같음.\n",
        "Q = input_sums\n",
        "K = input_sums\n",
        "V = input_sums\n",
        "\n",
        "# padding으로 설정했던 부분은 masked.\n",
        "attn_mask = inputs.eq(0).unsqueeze(1).expand(Q.size(0), Q.size(1), K.size(1))\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPgZ7YoXjtFu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "469b354a-fda9-4096-faf7-abf8baac6a38"
      },
      "source": [
        "# matrix multiplication, Q * K^T\n",
        "scores = torch.matmul(Q, K.transpose(-1, -2))\n",
        "print(scores.size())\n",
        "print(scores[0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 8, 8])\n",
            "tensor([[220.7007,  62.3027,  52.2023,  43.3869,  37.7986,  70.7991,  63.8554,\n",
            "          63.8554],\n",
            "        [ 62.3027, 140.0178,  42.8987,  36.1452,  28.2566,  43.7788,  57.3529,\n",
            "          57.3529],\n",
            "        [ 52.2023,  42.8987, 197.8656,  36.3456,  71.4895,  76.1569,  57.1159,\n",
            "          57.1159],\n",
            "        [ 43.3869,  36.1452,  36.3456, 152.3838,  69.6505,  43.8249,  32.9101,\n",
            "          32.9101],\n",
            "        [ 37.7986,  28.2566,  71.4895,  69.6505, 164.1191,  58.0175,  46.9227,\n",
            "          46.9227],\n",
            "        [ 70.7991,  43.7788,  76.1569,  43.8249,  58.0175, 223.8021,  46.2688,\n",
            "          46.2688],\n",
            "        [ 63.8554,  57.3529,  57.1159,  32.9101,  46.9227,  46.2688, 223.7537,\n",
            "         223.7537],\n",
            "        [ 63.8554,  57.3529,  57.1159,  32.9101,  46.9227,  46.2688, 223.7537,\n",
            "         223.7537]], grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_Y2p7FTj9b6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "87dd5602-e397-40dd-e1c6-677816e1aa5c"
      },
      "source": [
        "# scaling\n",
        "d_head = 64\n",
        "scores = scores.mul_(1/d_head**0.5)\n",
        "print(scores.size())\n",
        "print(scores[0])"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 8, 8])\n",
            "tensor([[27.5876,  7.7878,  6.5253,  5.4234,  4.7248,  8.8499,  7.9819,  7.9819],\n",
            "        [ 7.7878, 17.5022,  5.3623,  4.5181,  3.5321,  5.4723,  7.1691,  7.1691],\n",
            "        [ 6.5253,  5.3623, 24.7332,  4.5432,  8.9362,  9.5196,  7.1395,  7.1395],\n",
            "        [ 5.4234,  4.5181,  4.5432, 19.0480,  8.7063,  5.4781,  4.1138,  4.1138],\n",
            "        [ 4.7248,  3.5321,  8.9362,  8.7063, 20.5149,  7.2522,  5.8653,  5.8653],\n",
            "        [ 8.8499,  5.4723,  9.5196,  5.4781,  7.2522, 27.9753,  5.7836,  5.7836],\n",
            "        [ 7.9819,  7.1691,  7.1395,  4.1138,  5.8653,  5.7836, 27.9692, 27.9692],\n",
            "        [ 7.9819,  7.1691,  7.1395,  4.1138,  5.8653,  5.7836, 27.9692, 27.9692]],\n",
            "       grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqIMhaetkAiH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "e7144485-bcb4-49cc-dbd0-bd6d10d5d4aa"
      },
      "source": [
        "scores.masked_fill_(attn_mask, -1e9)\n",
        "print(scores.size())\n",
        "print(scores[0])"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 8, 8])\n",
            "tensor([[ 2.7588e+01,  7.7878e+00,  6.5253e+00,  5.4234e+00,  4.7248e+00,\n",
            "          8.8499e+00, -1.0000e+09, -1.0000e+09],\n",
            "        [ 7.7878e+00,  1.7502e+01,  5.3623e+00,  4.5181e+00,  3.5321e+00,\n",
            "          5.4723e+00, -1.0000e+09, -1.0000e+09],\n",
            "        [ 6.5253e+00,  5.3623e+00,  2.4733e+01,  4.5432e+00,  8.9362e+00,\n",
            "          9.5196e+00, -1.0000e+09, -1.0000e+09],\n",
            "        [ 5.4234e+00,  4.5181e+00,  4.5432e+00,  1.9048e+01,  8.7063e+00,\n",
            "          5.4781e+00, -1.0000e+09, -1.0000e+09],\n",
            "        [ 4.7248e+00,  3.5321e+00,  8.9362e+00,  8.7063e+00,  2.0515e+01,\n",
            "          7.2522e+00, -1.0000e+09, -1.0000e+09],\n",
            "        [ 8.8499e+00,  5.4723e+00,  9.5196e+00,  5.4781e+00,  7.2522e+00,\n",
            "          2.7975e+01, -1.0000e+09, -1.0000e+09],\n",
            "        [ 7.9819e+00,  7.1691e+00,  7.1395e+00,  4.1138e+00,  5.8653e+00,\n",
            "          5.7836e+00, -1.0000e+09, -1.0000e+09],\n",
            "        [ 7.9819e+00,  7.1691e+00,  7.1395e+00,  4.1138e+00,  5.8653e+00,\n",
            "          5.7836e+00, -1.0000e+09, -1.0000e+09]], grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErAwpWvkkE8v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "5e22286e-c4c5-4a58-9912-2e4dad014d9d"
      },
      "source": [
        "# softmax, weight distribution을 구한다.\n",
        "attn_prob = nn.Softmax(dim=-1)(scores)\n",
        "print(attn_prob.size())\n",
        "print(attn_prob[0])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 8, 8])\n",
            "tensor([[1.0000e+00, 2.5181e-09, 7.1246e-10, 2.3670e-10, 1.1771e-10, 7.2832e-09,\n",
            "         0.0000e+00, 0.0000e+00],\n",
            "        [6.0404e-05, 9.9993e-01, 5.3418e-06, 2.2964e-06, 8.5666e-07, 5.9629e-06,\n",
            "         0.0000e+00, 0.0000e+00],\n",
            "        [1.2371e-08, 3.8667e-09, 1.0000e+00, 1.7045e-09, 1.3786e-07, 2.4707e-07,\n",
            "         0.0000e+00, 0.0000e+00],\n",
            "        [1.2103e-06, 4.8951e-07, 5.0193e-07, 9.9996e-01, 3.2260e-05, 1.2784e-06,\n",
            "         0.0000e+00, 0.0000e+00],\n",
            "        [1.3882e-07, 4.2116e-08, 9.3633e-06, 7.4404e-06, 9.9998e-01, 1.7381e-06,\n",
            "         0.0000e+00, 0.0000e+00],\n",
            "        [4.9426e-09, 1.6870e-10, 9.6563e-09, 1.6967e-10, 1.0002e-09, 1.0000e+00,\n",
            "         0.0000e+00, 0.0000e+00],\n",
            "        [4.7024e-01, 2.0860e-01, 2.0251e-01, 9.8264e-03, 5.6636e-02, 5.2191e-02,\n",
            "         0.0000e+00, 0.0000e+00],\n",
            "        [4.7024e-01, 2.0860e-01, 2.0251e-01, 9.8264e-03, 5.6636e-02, 5.2191e-02,\n",
            "         0.0000e+00, 0.0000e+00]], grad_fn=<SelectBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-zOJ0VQkKTH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1f37fe87-56dc-4aa9-8253-77d1af246cdd"
      },
      "source": [
        "# weight distribution, value를 통해 가중 합을 구한다.\n",
        "context = torch.matmul(attn_prob, V)\n",
        "print(context.size())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 8, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nN7ngPC3sxut",
        "colab_type": "text"
      },
      "source": [
        "## ScaledDotProductAttention\n",
        "- 위의 과정을 하나의 class로 만들어 사용한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sL3cKGWhswhc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ScaledDotProductAttention(nn.Module):\n",
        "    def __init__(self, d_head):\n",
        "        super().__init__()\n",
        "        self.scale = 1 / (d_head ** 0.5)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n",
        "        scores.masked_fill_(attn_mask, -1e9)\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_prob = nn.Softmax(dim=-1)(scores)\n",
        "        # (bs, n_head, n_q_seq, d_v)\n",
        "        context = torch.matmul(attn_prob, V)\n",
        "        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n",
        "        return context, attn_prob"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snTAzbKCkqd8",
        "colab_type": "text"
      },
      "source": [
        "# 4. Multi-Head Attention\n",
        "- Q, K, V, attn_mask는 Scaled Dot Product Attention과 동일.\n",
        "- 여기선 head의 개수는 2개로 head의 dimension은 128/2 = 64가 된다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPvTvhpikcxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Q = input_sums\n",
        "K = input_sums\n",
        "V = input_sums\n",
        "attn_mask = inputs.eq(0).unsqueeze(1).expand(Q.size(0), Q.size(1), K.size(1))\n",
        "\n",
        "batch_size = Q.size(0)\n",
        "n_head = 2"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nh1U2cXdlH8u",
        "colab_type": "text"
      },
      "source": [
        "- Q, K, V를 Multi Head로 만드는 과정."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GbhcmWXhlFlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "W_Q = nn.Linear(d_hidn, n_head * d_head)\n",
        "W_K = nn.Linear(d_hidn, n_head * d_head)\n",
        "W_V = nn.Linear(d_hidn, n_head * d_head)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoD91xxKld_8",
        "colab_type": "text"
      },
      "source": [
        "https://stackoverflow.com/questions/54916135/what-is-the-class-definition-of-nn-linear-in-pytorch\n",
        "\n",
        "- nn.Linear(in_features, out_features, bias=True)\n",
        "  - 주어진 데이터에 대해 linear transformation을 적용한다.\n",
        "  - in_features : input sample의 사이즈\n",
        "  - out_features : output sample의 사이즈\n",
        "  - bias\n",
        "- (y = wx + b)에서, linear transformation의 weight, bias 는 랜덤하게 초기화된다.\n",
        "  - fully connected layer, 입력값을 동일하게 넣어도 다른 결과값이 나오게 됨. Q,K,V 각각의 Weight Matrix를 다르게 만들기 위한 방법으로 활용.\n",
        "\n",
        "- 위 코드\n",
        "  - in_features : 128(hidden feature dimension)\n",
        "  - out_features : 2 * 64 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Go35H0Rn5aD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "83a94066-6483-4bf4-a67d-eadea66d040d"
      },
      "source": [
        "q_s = W_Q(Q).view(batch_size, -1, n_head, d_head).transpose(1,2)\n",
        "# (bs, n_head, n_seq, d_head)\n",
        "k_s = W_K(K).view(batch_size, -1, n_head, d_head).transpose(1,2)\n",
        "# (bs, n_head, n_seq, d_head)\n",
        "v_s = W_V(V).view(batch_size, -1, n_head, d_head).transpose(1,2)\n",
        "print(q_s.size(), k_s.size(), v_s.size())"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 2, 8, 64]) torch.Size([2, 2, 8, 64]) torch.Size([2, 2, 8, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DivgGMVCoAe2",
        "colab_type": "text"
      },
      "source": [
        "- 기존의 128 크기를 갖는 q_s를 랜덤하게 선형 변환시킨 q_s가 나오고, 이를 view()함수를 통해 multi-head로 바꿔줌.\n",
        "\n",
        "-  [tensor.view()](https://pytorch.org/docs/stable/tensor_view.html) : base tensor와 같은 데이터를 공유.\n",
        "  - "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyKXsg4Dn__e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# attention mask도 똑같이 변경.\n",
        "attn_mask = attn_mask.unsqueeze(1).repeat(1, n_head, 1, 1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHNTWyC4sb9s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaled_dot_attn = ScaledDotProductAttention(d_head)\n",
        "context, attn_prob = scaled_dot_attn(q_s, k_s, v_s, attn_mask)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwM4HUgLsk3A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "1226c2e9-0c25-4abd-bc5d-d0f2d781cb6e"
      },
      "source": [
        "print(context.size())\n",
        "print(attn_prob.size())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 2, 8, 64])\n",
            "torch.Size([2, 2, 8, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yh8mHFU8tHON",
        "colab_type": "text"
      },
      "source": [
        "### concat"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhRFhYOWs-rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_head * d_head)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xvMZ803tQi0",
        "colab_type": "text"
      },
      "source": [
        "### Linear Transformation (W_0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlTQCKZxtJsi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "86d2efe1-013f-4315-d101-3c3f14141e90"
      },
      "source": [
        "linear = nn.Linear(n_head * d_head, d_hidn)\n",
        "# (bs, n_seq, d_hidn)\n",
        "output = linear(context)\n",
        "print(output.size())"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 8, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tL2EpSPtbt8",
        "colab_type": "text"
      },
      "source": [
        "## MultiHeadAttention Class\n",
        "- 위의 과정을 Class로 만들어 사용."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVXR7ztXtXzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" multi head attention \"\"\"\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_hidn, n_head, d_head):\n",
        "        super().__init__()\n",
        "        self.d_hidn = d_hidn\n",
        "        self.n_head = n_head\n",
        "        self.d_head = d_head\n",
        "\n",
        "        self.W_Q = nn.Linear(d_hidn, n_head * d_head)\n",
        "        self.W_K = nn.Linear(d_hidn, n_head * d_head)\n",
        "        self.W_V = nn.Linear(d_hidn, n_head * d_head)\n",
        "        self.scaled_dot_attn = ScaledDotProductAttention(d_head)\n",
        "        self.linear = nn.Linear(n_head * d_head, d_hidn)\n",
        "    \n",
        "    def forward(self, Q, K, V, attn_mask):\n",
        "        batch_size = Q.size(0)\n",
        "        # (bs, n_head, n_q_seq, d_head)\n",
        "        q_s = self.W_Q(Q).view(batch_size, -1, self.n_head, self.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_k_seq, d_head)\n",
        "        k_s = self.W_K(K).view(batch_size, -1, self.n_head, self.d_head).transpose(1,2)\n",
        "        # (bs, n_head, n_v_seq, d_head)\n",
        "        v_s = self.W_V(V).view(batch_size, -1, self.n_head, self.d_head).transpose(1,2)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, n_k_seq)\n",
        "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_head, 1, 1)\n",
        "\n",
        "        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n",
        "        # (bs, n_head, n_q_seq, h_head * d_head)\n",
        "        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_head * self.d_head)\n",
        "        # (bs, n_head, n_q_seq, e_embd)\n",
        "        output = self.linear(context)\n",
        "        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n",
        "        return output, attn_prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX0uRpbNtlBD",
        "colab_type": "text"
      },
      "source": [
        "# 5. Masked MultiHeadAttention (생략)\n",
        "- encoder에서는 안 쓰여서 일단 생략함"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyugKZ7St2iz",
        "colab_type": "text"
      },
      "source": [
        "# 6. FeedForward Neural Network(FFNN)\n",
        "- W0, W1을 통해 구성한 Feed-Forward NN\n",
        "- activation layer로 넣은듯."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07Qr61wYt1qx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "68aa8af1-1fb0-41b0-8c58-c384516f7e2c"
      },
      "source": [
        "conv1 = nn.Conv1d(in_channels=d_hidn, out_channels=d_hidn * 4, kernel_size=1)\n",
        "# (bs, d_hidn * 4, n_seq)\n",
        "ff_1 = conv1(output.transpose(1, 2))\n",
        "print(ff_1.size())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 512, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOWJopHeuSqG",
        "colab_type": "text"
      },
      "source": [
        "-"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRSJ7nPvt7mA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "active = F.gelu\n",
        "ff_2 = active(ff_1)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaJu3N8NuwHk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9bd4458f-8150-4cea-ef27-68ea6eafec9c"
      },
      "source": [
        "conv2 = nn.Conv1d(in_channels=d_hidn * 4, out_channels=d_hidn, kernel_size=1)\n",
        "ff_3 = conv2(ff_2).transpose(1, 2)\n",
        "print(ff_3.size())"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 8, 128])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WxqXqJwwu2X1",
        "colab_type": "text"
      },
      "source": [
        "## Feed Forward NN Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60Ie6Y2zuzD6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\" feed forward \"\"\"\n",
        "class PoswiseFeedForwardNet(nn.Module):\n",
        "    def __init__(self, d_hidn):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_hidn * 4, kernel_size=1)\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.config.d_hidn * 4, out_channels=self.config.d_hidn, kernel_size=1)\n",
        "        self.active = F.gelu\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # (bs, d_ff, n_seq)\n",
        "        output = self.active(self.conv1(inputs.transpose(1, 2)))\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        output = self.conv2(output).transpose(1, 2)\n",
        "        # (bs, n_seq, d_hidn)\n",
        "        return output"
      ],
      "execution_count": 47,
      "outputs": []
    }
  ]
}